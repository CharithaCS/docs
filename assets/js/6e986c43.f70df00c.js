"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[9529],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=c(n),d=r,k=m["".concat(s,".").concat(d)]||m[d]||u[d]||o;return n?a.createElement(k,i(i({ref:t},p),{},{components:n})):a.createElement(k,i({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5162:(e,t,n)=>{n.d(t,{Z:()=>i});var a=n(7294),r=n(6010);const o="tabItem_Ymn6";function i(e){let{children:t,hidden:n,className:i}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(o,i),hidden:n},t)}},5488:(e,t,n)=>{n.d(t,{Z:()=>d});var a=n(7462),r=n(7294),o=n(6010),i=n(2389),l=n(7392),s=n(7094),c=n(2466);const p="tabList__CuJ",u="tabItem_LNqP";function m(e){var t,n;const{lazy:i,block:m,defaultValue:d,values:k,groupId:g,className:h}=e,f=r.Children.map(e.children,(e=>{if((0,r.isValidElement)(e)&&"value"in e.props)return e;throw new Error("Docusaurus error: Bad <Tabs> child <"+("string"==typeof e.type?e.type:e.type.name)+'>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.')})),y=null!=k?k:f.map((e=>{let{props:{value:t,label:n,attributes:a}}=e;return{value:t,label:n,attributes:a}})),b=(0,l.l)(y,((e,t)=>e.value===t.value));if(b.length>0)throw new Error('Docusaurus error: Duplicate values "'+b.map((e=>e.value)).join(", ")+'" found in <Tabs>. Every value needs to be unique.');const v=null===d?d:null!=(t=null!=d?d:null==(n=f.find((e=>e.props.default)))?void 0:n.props.value)?t:f[0].props.value;if(null!==v&&!y.some((e=>e.value===v)))throw new Error('Docusaurus error: The <Tabs> has a defaultValue "'+v+'" but none of its children has the corresponding value. Available values are: '+y.map((e=>e.value)).join(", ")+". If you intend to show no default tab, use defaultValue={null} instead.");const{tabGroupChoices:w,setTabGroupChoices:N}=(0,s.U)(),[C,z]=(0,r.useState)(v),T=[],{blockElementScrollPositionUntilNextRender:S}=(0,c.o5)();if(null!=g){const e=w[g];null!=e&&e!==C&&y.some((t=>t.value===e))&&z(e)}const A=e=>{const t=e.currentTarget,n=T.indexOf(t),a=y[n].value;a!==C&&(S(t),z(a),null!=g&&N(g,String(a)))},O=e=>{var t;let n=null;switch(e.key){case"ArrowRight":{var a;const t=T.indexOf(e.currentTarget)+1;n=null!=(a=T[t])?a:T[0];break}case"ArrowLeft":{var r;const t=T.indexOf(e.currentTarget)-1;n=null!=(r=T[t])?r:T[T.length-1];break}}null==(t=n)||t.focus()};return r.createElement("div",{className:(0,o.Z)("tabs-container",p)},r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,o.Z)("tabs",{"tabs--block":m},h)},y.map((e=>{let{value:t,label:n,attributes:i}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:C===t?0:-1,"aria-selected":C===t,key:t,ref:e=>T.push(e),onKeyDown:O,onFocus:A,onClick:A},i,{className:(0,o.Z)("tabs__item",u,null==i?void 0:i.className,{"tabs__item--active":C===t})}),null!=n?n:t)}))),i?(0,r.cloneElement)(f.filter((e=>e.props.value===C))[0],{className:"margin-top--md"}):r.createElement("div",{className:"margin-top--md"},f.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==C})))))}function d(e){const t=(0,i.Z)();return r.createElement(m,(0,a.Z)({key:String(t)},e))}},7207:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var a=n(7462),r=(n(7294),n(3905)),o=n(5488),i=n(5162);const l={sidebar_position:2,title:"Simple, secure Kafka access"},s=void 0,c={unversionedId:"quick-tutorials/k8s-kafka-mtls",id:"quick-tutorials/k8s-kafka-mtls",title:"Simple, secure Kafka access",description:"This tutorial will walk you through declaring and applying intents to easily secure access to Kafka running inside a Kubernetes cluster,",source:"@site/docs/quick-tutorials/k8s-kafka-mtls.mdx",sourceDirName:"quick-tutorials",slug:"/quick-tutorials/k8s-kafka-mtls",permalink:"/quick-tutorials/k8s-kafka-mtls",draft:!1,editUrl:"https://github.com/otterize/docs/edit/main/docs/quick-tutorials/k8s-kafka-mtls.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,title:"Simple, secure Kafka access"},sidebar:"docSidebar",previous:{title:"NetworkPolicy automation",permalink:"/quick-tutorials/k8s-network-policies"},next:{title:"Kubernetes cluster mapping",permalink:"/quick-tutorials/k8s-network-mapper"}},p={},u=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Create an Otterize Cloud account",id:"create-an-otterize-cloud-account",level:4},{value:"Install Otterize OSS, connected to Otterize Cloud",id:"install-otterize-oss-connected-to-otterize-cloud",level:4},{value:"Install Kafka",id:"install-kafka",level:2},{value:"Configure Otterize to manage Kafka access",id:"configure-otterize-to-manage-kafka-access",level:2},{value:"Deploy clients",id:"deploy-clients",level:2},{value:"Optional: Install Otterize CLI and examine topic-level Kafka access map",id:"optional-install-otterize-cli-and-examine-topic-level-kafka-access-map",level:2},{value:"Apply intents",id:"apply-intents",level:2},{value:"What did we accomplish?",id:"what-did-we-accomplish",level:2},{value:"One-time setups:",id:"one-time-setups",level:3},{value:"Per-client setups:",id:"per-client-setups",level:3},{value:"What&#39;s next",id:"whats-next",level:2},{value:"Teardown",id:"teardown",level:2}],m={toc:u};function d(e){let{components:t,...l}=e;return(0,r.kt)("wrapper",(0,a.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This tutorial will walk you through declaring and applying intents to easily secure access to Kafka running inside a Kubernetes cluster,\nautomating the management of Kafka ACLs, and the generation and deployment of certificates for mTLS between Kafka and its clients."),(0,r.kt)("p",null,"In this tutorial, we will:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Deploy a Kafka broker, and three clients that call it."),(0,r.kt)("li",{parentName:"ul"},"Discover the topic-level access those clients require, using the Otterize network mapper's Kafka watcher."),(0,r.kt)("li",{parentName:"ul"},"Declare that one client pod intends to access a topic on Kafka."),(0,r.kt)("li",{parentName:"ul"},"See that an ACL was autogenerated to allow just that, while blocking calls from the other client."),(0,r.kt)("li",{parentName:"ul"},"See that mTLS credentials were autogenerated.")),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},"For this tutorial, we'll configure Otterize to not manage network policies, so we can focus on topic-level Kafka ACL authorization (vs just accessing Kafka at all)."),(0,r.kt)("p",{parentName:"admonition"},"Of course you can also choose to combine them ","\u2014"," after all, Kafka is just another service running in the cluster. To do that, reinstall Otterize without the ",(0,r.kt)("inlineCode",{parentName:"p"},"--set intentsOperator.operator.enableNetworkPolicyCreation=false")," flag.")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Prepare a Kubernetes cluster"),(0,r.kt)("p",null,"Before you start, you'll need a Kubernetes cluster."),(0,r.kt)("p",null,"Below are instructions for setting up a Kubernetes cluster with network policies.\nIf you don't have a cluster already, we recommend starting out with a Minikube cluster."),(0,r.kt)(o.Z,{groupId:"cni",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"minikube",label:"Minikube",mdxType:"TabItem"},(0,r.kt)("p",null,"If you don't have the Minikube CLI, first ",(0,r.kt)("a",{parentName:"p",href:"https://minikube.sigs.k8s.io/docs/start/"},"install it"),". "),(0,r.kt)("p",null,"Then start your Minikube cluster with Calico, in order to enforce network policies."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"minikube start --cpus=4 --memory 8192 --disk-size 32g --cni=calico\n")),(0,r.kt)("p",null,"The increased CPU, memory and disk resource allocations are required to be able to deploy the ecommerce app used in the visual tutorials successfully.")),(0,r.kt)(i.Z,{value:"gke",label:"Google GKE",mdxType:"TabItem"},(0,r.kt)("a",{href:"https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy#gcloud"},"Visit the official documentation"),", or follow the instructions below:",(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"cli",label:"gcloud CLI",mdxType:"TabItem"},(0,r.kt)("p",null,"To use the gcloud CLI for this tutorial, first ",(0,r.kt)("a",{parentName:"p",href:"https://cloud.google.com/sdk/docs/install"},"install")," and then\n",(0,r.kt)("a",{parentName:"p",href:"https://cloud.google.com/sdk/docs/initializing"},"initialize")," it."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"To enable network policy enforcement when creating a new cluster:"))),(0,r.kt)("p",null,"Run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters create CLUSTER_NAME --enable-network-policy --zone=ZONE\n")),(0,r.kt)("p",null,"(Replace ",(0,r.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the new cluster and ",(0,r.kt)("inlineCode",{parentName:"p"},"ZONE")," with your zone.)"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"To enable network policy enforcement for an existing cluster, perform the following tasks:"))),(0,r.kt)("p",null,"Run the following command to enable the add-on:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters update CLUSTER_NAME --update-addons=NetworkPolicy=ENABLED\n")),(0,r.kt)("p",null,"(Replace ",(0,r.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the cluster.)"),(0,r.kt)("p",null,"Then enable network policy enforcement on your cluster, re-creating your cluster's node pools with network policy enforcement enabled:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"gcloud container clusters update CLUSTER_NAME --enable-network-policy\n")),(0,r.kt)("p",null,"(Replace ",(0,r.kt)("inlineCode",{parentName:"p"},"CLUSTER_NAME")," with the name of the cluster.)")),(0,r.kt)(i.Z,{value:"console",label:"Console",mdxType:"TabItem"},(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"To enable network policy enforcement when creating a new cluster:"))),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to the Google Kubernetes Engine page in the Google Cloud console.\nThe remaining steps will appear automatically in the Google Cloud console.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"On the Google Kubernetes Engine page, click Create.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Configure your cluster as desired.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"From the navigation pane, under Cluster, click Networking.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click Create."))),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"To enable network policy enforcement for an existing cluster:"))),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Go to the Google Kubernetes Engine page in the Google Cloud console. The remaining steps will appear automatically in the Google Cloud console.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"In the cluster list, click the name of the cluster you want to modify.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Under Networking, in the Network policy field, click Edit network policy.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy for master and click Save Changes.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Wait for your changes to apply, and then click Edit network policy again.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Select the checkbox to Enable network policy for nodes.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Click Save Changes.")))))),(0,r.kt)(i.Z,{value:"eks",label:"AWS EKS",mdxType:"TabItem"},(0,r.kt)("a",{href:"https://docs.aws.amazon.com/eks/latest/userguide/calico.html"},"Visit the official documentation"),", or follow the instructions below:",(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Spin up an ",(0,r.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html"},"EKS cluster")," using the console, AWS CLI or ",(0,r.kt)("inlineCode",{parentName:"li"},"eksctl"),"."),(0,r.kt)("li",{parentName:"ol"},"Install Calico for network policy enforcement, without replacing the CNI:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/v1.12.6/config/master/calico-operator.yaml\nkubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/v1.12.6/config/master/calico-crs.yaml\n"))),(0,r.kt)(i.Z,{value:"aks",label:"Azure AKS",mdxType:"TabItem"},(0,r.kt)("p",null,"You can set up an AKS cluster using this ",(0,r.kt)("a",{parentName:"p",href:"https://learn.microsoft.com/en-us/azure/aks/learn/quick-kubernetes-deploy-cli"},"guide"),"."),(0,r.kt)("p",null,"For network policy support, no setup is required: Azure AKS comes with a built-in network policy implementation called Azure Network Policy Manager. You can choose whether you'd like to use this option or Calico when you create a cluster."),(0,r.kt)("a",{href:"https://learn.microsoft.com/en-us/azure/aks/use-network-policies"}," Read more at the official documentation site"),"."))),(0,r.kt)("p",null,"You can now install (or reinstall) Otterize in your cluster, and optionally connect to Otterize Cloud. Connecting to Cloud lets you:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},'See what\'s happening visually in your browser, through the "access graph";'),(0,r.kt)("li",{parentName:"ol"},"Avoid using SPIRE (which can be installed with Otterize) for issuing certificates, as Otterize Cloud provides a certificate service.")),(0,r.kt)("p",null,"So either forego browser visualization and:"),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Install Otterize in your cluster with the Kafka watcher enabled, ",(0,r.kt)("b",null,"without")," Otterize Cloud (and no network policy management)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'helm repo add otterize https://helm.otterize.com\nhelm repo update\nhelm install otterize otterize/otterize-kubernetes -n otterize-system --create-namespace \\\n--set intentsOperator.operator.enableNetworkPolicyCreation=false \\\n--set networkMapper.kafkawatcher.enable=true \\\n--set networkMapper.kafkawatcher.kafkaServers={"kafka-0.kafka"}\n')),(0,r.kt)("p",null,"This chart is a bundle of the Otterize intents operator, Otterize credentials operator, Otterize network mapper, and SPIRE.\nInitial deployment may take a couple of minutes.\nYou can add the ",(0,r.kt)("inlineCode",{parentName:"p"},"--wait")," flag for Helm to wait for deployment to complete and all pods to be Ready, or manually watch for all pods to be ",(0,r.kt)("inlineCode",{parentName:"p"},"Ready")," using ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pods -n otterize-system -w"),".")),(0,r.kt)("p",null,"Or choose to include browser visualization and:"),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Install Otterize in your cluster, ",(0,r.kt)("b",null,"with")," Otterize Cloud (and no network policy management)"),(0,r.kt)("h4",{id:"create-an-otterize-cloud-account"},"Create an Otterize Cloud account"),(0,r.kt)("p",null,"If you don't already have an account, browse to ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"https://app.otterize.com")," to set one up."),(0,r.kt)("p",null,"If someone in your team has already created an org in Otterize Cloud, and invited you (using your email address), you may see an invitation to accept."),(0,r.kt)("p",null,"Otherwise, you'll create a new org, which you can later rename, and invite your teammates to join you there."),(0,r.kt)("h4",{id:"install-otterize-oss-connected-to-otterize-cloud"},"Install Otterize OSS, connected to Otterize Cloud"),(0,r.kt)("p",null,'If no Kubernetes clusters are connected to your account, click the "connect your cluster" button to:'),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Create a Cloud cluster object, specifying its name and the name of an environment to which all namespaces in that cluster will belong, by default."),(0,r.kt)("li",{parentName:"ol"},'Connect it with your actual Kubernetes cluster, by clicking on the "Connection guide ',"\u2192",'" link and running the Helm commands shown there.',(0,r.kt)("ol",{parentName:"li"},(0,r.kt)("li",{parentName:"ol"},"Follow the instructions to install Otterize ",(0,r.kt)("b",null,"with enforcement on")," (not in shadow mode) for this tutorial. In other words, ",(0,r.kt)("b",null,"omit")," the following flag in the Helm command: ",(0,r.kt)("inlineCode",{parentName:"li"},"--set intentsOperator.operator.enableEnforcement=false")," "),(0,r.kt)("li",{parentName:"ol"},"And ",(0,r.kt)("b",null,"add")," the following flags to the Helm command: ",(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre"},'--set intentsOperator.operator.enableNetworkPolicyCreation=false \\ \n--set networkMapper.kafkawatcher.enable=true \\\n--set networkMapper.kafkawatcher.kafkaServers={"kafka-0.kafka"}\n')))))),(0,r.kt)("details",null,(0,r.kt)("summary",null,"More details, if you're curious"),(0,r.kt)("p",null,"Connecting your cluster simply entails installing Otterize OSS via Helm, using credentials from your account so Otterize OSS can report information needed to visualize the cluster."),(0,r.kt)("p",null,"The credentials will already be inlined into the Helm command shown in the Cloud UI, so you just need to copy that line and run it from your shell.\nIf you don't give it the Cloud credentials, Otterize OSS will run fully standalone in your cluster ","\u2014"," you just won't have the visualization in Otterize Cloud."),(0,r.kt)("p",null,'The Helm command shown in the Cloud UI also includes flags to turn off enforcement: Otterize OSS will be running in "shadow mode," meaning that it will show you what ',(0,r.kt)("strong",{parentName:"p"},"would")," happen if it created network policies to restrict pod-to-pod traffic, and created Kafka ACLs to control access to Kafka topics. While that's useful for gradually rolling out IBAC, for this tutorial we go straight to active enforcement."),(0,r.kt)("p",null,"While we want enforcement turned on, in this tutorial we don't want it for network policies ","\u2014"," only for Kafka, so we can focus on Kafka topic-level access. You can configure network policy shadow or active enforcement, and Kafka ACLs shadow or active enforcement, independently of each other.s"))),(0,r.kt)("h2",{id:"install-kafka"},"Install Kafka"),(0,r.kt)("p",null,"We will deploy a Kafka cluster using Bitnami's ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/bitnami/charts/tree/master/bitnami/kafka"},"Helm chart"),".\nIn the chart we will configure Kafka to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Recognize the Otterize intents operator as a super user so it can configure ACLs;"),(0,r.kt)("li",{parentName:"ul"},"Turn on Kafka debug logging to allow the Kafka watcher to feed topic-level client access information to the network mapper;"),(0,r.kt)("li",{parentName:"ul"},"Use TLS (Kafka calls it SSL) for its listeners;"),(0,r.kt)("li",{parentName:"ul"},"Tell the Otterize credentials operator, via pod annotations, how credentials should be created;"),(0,r.kt)("li",{parentName:"ul"},"Authenticate clients using mTLS credentials provided as a Kubernetes secret; and"),(0,r.kt)("li",{parentName:"ul"},"Allow access to any topic by default unless denied by an ACL.")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see the Helm values.yaml used with the Bitnami chart"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'# Configure Otterize as a super user to grant it access to configure ACLs\nsuperUsers: "User:CN=kafka.kafka,O=SPIRE,C=US;User:CN=intents-operator-controller-manager.otterize,O=SPIRE,C=US"\n# Use TLS for the Kafka listeners (Kafka calls them SSL)\nlisteners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\nadvertisedListeners:\n  - "CLIENT://:9092"\n  - "INTERNAL://:9093"\nlistenerSecurityProtocolMap: "INTERNAL:SSL,CLIENT:SSL"\n# For a gradual rollout scenario we will want to keep the default permission for topics as allowed, unless an ACL was set\nallowEveryoneIfNoAclFound: true\n# Annotations for Otterize to generate credentials\npodAnnotations:\n  credentials-operator.otterize.com/cert-type: jks\n  credentials-operator.otterize.com/tls-secret-name: kafka-tls-secret\n  credentials-operator.otterize.com/truststore-file-name: kafka.truststore.jks\n  credentials-operator.otterize.com/keystore-file-name: kafka.keystore.jks\n  credentials-operator.otterize.com/dns-names: "kafka-0.kafka-headless.kafka.svc.cluster.local,kafka.kafka.svc.cluster.local"\n# Authenticate clients using mTLS\nauth:\n  clientProtocol: mtls\n  interBrokerProtocol: mtls\n  tls:\n    type: jks\n    existingSecrets:\n      - kafka-tls-secret\n    password: password\nauthorizerClassName: kafka.security.authorizer.AclAuthorizer\n# Allocate resources\nresources:\n  requests:\n    cpu: 50m\n    memory: 256Mi\nlog4j: |\n  # Unspecified loggers and loggers with additivity=true output to server.log and stdout\n  # Note that INFO only applies to unspecified loggers, the log level of the child logger is used otherwise\n  \n  log4j.rootLogger=INFO, stdout, kafkaAppender\n\n  log4j.appender.stdout=org.apache.log4j.ConsoleAppender\n  log4j.appender.stdout.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.kafkaAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.kafkaAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.kafkaAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.stateChangeAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.stateChangeAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.stateChangeAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.requestAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.requestAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.requestAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.cleanerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.cleanerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.cleanerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.controllerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.controllerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.controllerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n  \n  log4j.appender.authorizerAppender=org.apache.log4j.ConsoleAppender\n  log4j.appender.authorizerAppender.layout=org.apache.log4j.PatternLayout\n  log4j.appender.authorizerAppender.layout.ConversionPattern=[%d] %p %m (%c)%n\n\n\n  # Change the line below to adjust ZK client logging\n  log4j.logger.org.apache.zookeeper=INFO\n\n  # Change the two lines below to adjust the general broker logging level (output to server.log and stdout)\n  log4j.logger.kafka=INFO, stdout\n  log4j.logger.org.apache.kafka=INFO\n\n  # Change to DEBUG or TRACE to enable request logging\n  log4j.logger.kafka.request.logger=WARN, requestAppender\n  log4j.additivity.kafka.request.logger=false\n\n  # Uncomment the lines below and change log4j.logger.kafka.network.RequestChannel$ to TRACE for additional output\n  # related to the handling of requests\n  #log4j.logger.kafka.network.Processor=TRACE, requestAppender\n  #log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender\n  #log4j.additivity.kafka.server.KafkaApis=false\n  log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender\n  log4j.additivity.kafka.network.RequestChannel$=false\n\n  # Change the line below to adjust KRaft mode controller logging\n  log4j.logger.org.apache.kafka.controller=INFO, controllerAppender\n  log4j.additivity.org.apache.kafka.controller=false\n\n  # Change the line below to adjust ZK mode controller logging\n  log4j.logger.kafka.controller=TRACE, controllerAppender\n  log4j.additivity.kafka.controller=false\n\n  log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender\n  log4j.additivity.kafka.log.LogCleaner=false\n\n  log4j.logger.state.change.logger=INFO, stateChangeAppender\n  log4j.additivity.state.change.logger=false\n\n  # Access denials are logged at INFO level, change to DEBUG to also log allowed accesses\n  log4j.logger.kafka.authorizer.logger=DEBUG, authorizerAppender\n  log4j.additivity.kafka.authorizer.logger=false\n'))),(0,r.kt)("p",null,"The following command will deploy a Kafka cluster with this chart:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add bitnami https://charts.bitnami.com/bitnami\nhelm repo update\nhelm install --create-namespace -n kafka \\\n  -f https://docs.otterize.com/code-examples/kafka-mtls/helm/values_debug_logging.yaml kafka bitnami/kafka --version 21.4.4\n")),(0,r.kt)("p",null,"You can watch for all pods to be ",(0,r.kt)("inlineCode",{parentName:"p"},"Ready")," using ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pods -n kafka -w"),"."),(0,r.kt)("h2",{id:"configure-otterize-to-manage-kafka-access"},"Configure Otterize to manage Kafka access"),(0,r.kt)("p",null,"Let's connect Kafka with Otterize by applying an Otterize ",(0,r.kt)("inlineCode",{parentName:"p"},"KafkaServerConfig"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://docs.otterize.com/code-examples/kafka-mtls/kafkaserverconfig.yaml\n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see the KafkaServerConfig"),(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"kafkaserverconfig.yaml",label:"kafkaserverconfig.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: k8s.otterize.com/v1alpha2\nkind: KafkaServerConfig\nmetadata:\n  name: kafkaserverconfig\n  namespace: kafka\nspec:\n  service:\n    name: kafka\n  addr: kafka.kafka:9092\n  tls:\n    certFile: /etc/otterize-spire/cert.pem\n    keyFile: /etc/otterize-spire/key.pem\n    rootCAFile: /etc/otterize-spire/ca.pem\n  topics:\n    - topic: "transactions"\n      pattern: literal\n      clientIdentityRequired: true\n      intentsRequired: false\n'))))),(0,r.kt)("p",null,"Upon applying the KafkaServerConfig, an ACL will configure Kafka to allow only authenticated access to the ",(0,r.kt)("em",{parentName:"p"},"transactions")," topic by denying all anonymous access.\nThis will be the base state, from which we will gradually roll out secure access to Kafka."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl logs -n kafka statefulset/kafka | grep "Processing Acl change" | grep ANONYMOUS | tail -n 1\n')),(0,r.kt)("p",null,"You should see the following output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[2023-05-18 11:49:14,230] INFO Processing Acl change notification for ResourcePattern(resourceType=TOPIC, name=transactions, patternType=LITERAL), versionedAcls : Set(User:ANONYMOUS has DENY permission for operations: ALL from hosts: *, User:* has ALLOW permission for operations: ALL from hosts: *), zkVersion : 0 (kafka.security.authorizer.AclAuthorizer)\n")),(0,r.kt)("h2",{id:"deploy-clients"},"Deploy clients"),(0,r.kt)("p",null,"Clients will authenticate to Kafka using mTLS. Otterize makes this easy, requiring just 3 simple changes to the client pod spec:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Generate credentials"),": add the ",(0,r.kt)("inlineCode",{parentName:"li"},"credentials-operator.otterize.com/tls-secret-name")," annotation, which tells Otterize to generate mTLS credentials and store them in a Kubernetes secret whose name is the value of this annotation."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Expose credentials in a volume"),": add a volume containing this secret to the pod."),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Mount the volume"),": mount the volume in every container in the pod.")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see this structure"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'spec:\n  template:\n    metadata:\n      annotations:\n        # highlight-next-line\n        # 1. Generate credentials as a secret called "client-credentials-secret":\n        credentials-operator.otterize.com/tls-secret-name: client-credentials-secret\n        ...\n    spec:\n      volumes:\n        # highlight-start\n        # 2. Create a volume containing this secret:\n        - name: otterize-credentials\n          secret:\n            secretName: client-credentials-secret\n        # highlight-end\n        ...\n      containers:\n        - name: client\n          ...\n          volumeMounts:\n            # highlight-start\n            # 3. Mount volume into container\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n            # highlight-end\n'))),(0,r.kt)("p",null,"Our simple example consists of a three client pods ","\u2014",' "client", "client-other", and "client-authenticated" ',"\u2014"," and the Kafka broker."),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see the client specs used in this example"),(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"namespace.yaml",label:"namespace.yaml",default:!0,mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: v1\nkind: Namespace\nmetadata:\n  name: otterize-tutorial-kafka-mtls\n"))),(0,r.kt)(i.Z,{value:"client-deployment.yaml",label:"client-deployment.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client\n  namespace: otterize-tutorial-kafka-mtls\nspec:\n  selector:\n    matchLabels:\n      app: client\n  template:\n    metadata:\n      labels:\n        app: client\n      annotations:\n        credentials-operator.otterize.com/tls-secret-name: client-credentials-secret\n    spec:\n      containers:\n        - name: client\n          image: golang\n          command: [ "/bin/sh", "-c", "--" ]\n          args: [ "while true; do cd /app; cp src/* .; go get main; go run .; sleep infinity; done" ]\n          volumeMounts:\n            - name: ephemeral\n              mountPath: /app\n            - mountPath: /app/src\n              name: client-go\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n      volumes:\n        - name: client-go\n          configMap:\n            name: client-go\n        - name: otterize-credentials\n          secret:\n            secretName: client-credentials-secret\n        - name: ephemeral\n          emptyDir: { }\n'))),(0,r.kt)(i.Z,{value:"client-configmap.yaml",label:"client-configmap.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: client-go\n  namespace: otterize-tutorial-kafka-mtls\ndata:\n  client.go: |\n    package main\n\n    import (\n        "crypto/tls"\n        "crypto/x509"\n        "fmt"\n        "github.com/Shopify/sarama"\n        "github.com/sirupsen/logrus"\n        "io/ioutil"\n        "time"\n    )\n    \n    const (\n        kafkaAddr     = "kafka.kafka:9092"\n        testTopicName = "mytopic"\n        certFile      = "/var/otterize/credentials/cert.pem"\n        keyFile       = "/var/otterize/credentials/key.pem"\n        rootCAFile    = "/var/otterize/credentials/ca.pem"\n    )\n    \n    func getTLSConfig() (*tls.Config, error) {\n        cert, err := tls.LoadX509KeyPair(certFile, keyFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading x509 key pair: %w", err)\n        }\n    \n        pool := x509.NewCertPool()\n        rootCAPEM, err := ioutil.ReadFile(rootCAFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading root CA PEM file: %w ", err)\n        }\n        pool.AppendCertsFromPEM(rootCAPEM)\n    \n        return &tls.Config{\n            Certificates: []tls.Certificate{cert},\n            RootCAs:      pool,\n        }, nil\n    }\n    \n    func send_messages(producer sarama.SyncProducer) {\n        i := 1\n        for {\n          msg := fmt.Sprintf("Message %d [sent by client]", i)\n          _, _, err := producer.SendMessage(&sarama.ProducerMessage{\n              Topic:     testTopicName,\n              Partition: -1,\n              Value:     sarama.StringEncoder(msg),\n          })\n          if err != nil {\n              return\n          }\n          fmt.Printf("Sent message - %s\\n", msg)\n          time.Sleep(2 * time.Second)\n          i++\n        }\n    }\n    \n    func loop_kafka() error {\n        addrs := []string{kafkaAddr}\n    \n        config := sarama.NewConfig()\n        fmt.Println("Loading mTLS certificates")\n        config.Net.TLS.Enable = true\n        tlsConfig, err := getTLSConfig()\n        if err != nil {\n            return err\n        }\n        config.Net.TLS.Config = tlsConfig\n        fmt.Println("Connecting to Kafka")\n        config.Net.DialTimeout = 5 * time.Second\n        config.Net.ReadTimeout = 5 * time.Second\n        config.Net.WriteTimeout = 5 * time.Second\n        client, err := sarama.NewClient(addrs, config)\n        if err != nil {\n            return err\n        }\n        fmt.Println("Creating a producer and a consumer for -", testTopicName)\n        config.Producer.Return.Successes = true\n        config.Producer.Timeout = 5 * time.Second\n        config.Consumer.MaxWaitTime = 5 * time.Second\n        config.Producer.Return.Errors = true\n        config.Consumer.Return.Errors = true\n        producer, err := sarama.NewSyncProducerFromClient(client)\n        if err != nil {\n            return err\n        }\n    \n        consumer, err := sarama.NewConsumerFromClient(client)\n        if err != nil {\n            return err\n        }\n        fmt.Println("Sending messages")\n        go send_messages(producer)\n    \n        partConsumer, err := consumer.ConsumePartition(testTopicName, 0, 0)\n        if err != nil {\n            return err\n        }\n    \n        for msg := range partConsumer.Messages() {\n            fmt.Printf("Read message - %s\\n", msg.Value)\n        }\n        return nil\n    }\n    \n    func main() {\n        for {\n            err := loop_kafka()\n            logrus.WithError(err).Println()\n            fmt.Println("Loop exited")\n            time.Sleep(2 * time.Second)\n        }\n    }\n\n\n  go.mod: |\n    module main\n            \n            go 1.18\n            \n            require (\n            github.com/Shopify/sarama v1.36.0\n            github.com/sirupsen/logrus v1.9.0\n            )\n            \n            require (\n            github.com/davecgh/go-spew v1.1.1 // indirect\n            github.com/eapache/go-resiliency v1.3.0 // indirect\n            github.com/eapache/go-xerial-snappy v0.0.0-20180814174437-776d5712da21 // indirect\n            github.com/eapache/queue v1.1.0 // indirect\n            github.com/golang/snappy v0.0.4 // indirect\n            github.com/hashicorp/errwrap v1.0.0 // indirect\n            github.com/hashicorp/go-multierror v1.1.1 // indirect\n            github.com/hashicorp/go-uuid v1.0.3 // indirect\n            github.com/jcmturner/aescts/v2 v2.0.0 // indirect\n            github.com/jcmturner/dnsutils/v2 v2.0.0 // indirect\n            github.com/jcmturner/gofork v1.7.6 // indirect\n            github.com/jcmturner/gokrb5/v8 v8.4.3 // indirect\n            github.com/jcmturner/rpc/v2 v2.0.3 // indirect\n            github.com/klauspost/compress v1.15.9 // indirect\n            github.com/pierrec/lz4/v4 v4.1.15 // indirect\n            github.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 // indirect\n            golang.org/x/crypto v0.0.0-20220722155217-630584e8d5aa // indirect\n            golang.org/x/net v0.0.0-20220809184613-07c6da5e1ced // indirect\n            golang.org/x/sys v0.0.0-20220728004956-3c1f35247d10 // indirect\n            )\n'))),(0,r.kt)(i.Z,{value:"client-other-deployment.yaml",label:"client-other-deployment.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client-other\n  namespace: otterize-tutorial-kafka-mtls\nspec:\n  selector:\n    matchLabels:\n      app: client-other\n  template:\n    metadata:\n      labels:\n        app: client-other\n      annotations:\n        credentials-operator.otterize.com/tls-secret-name: client-other-credentials-secret\n    spec:\n      containers:\n        - name: client-other\n          image: golang\n          command: [ "/bin/sh", "-c", "--" ]\n          args: [ "while true; do cd /app; cp src/* .; go get main; go run .; sleep infinity; done" ]\n          volumeMounts:\n            - name: ephemeral\n              mountPath: /app\n            - mountPath: /app/src\n              name: client-other-go\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n      volumes:\n        - name: client-other-go\n          configMap:\n            name: client-other-go\n        - name: otterize-credentials\n          secret:\n            secretName: client-other-credentials-secret\n        - name: ephemeral\n          emptyDir: { }\n'))),(0,r.kt)(i.Z,{value:"client-other-configmap.yaml",label:"client-other-configmap.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: client-other-go\n  namespace: otterize-tutorial-kafka-mtls\ndata:\n  client-other.go: |\n    package main\n    \n    import (\n        "crypto/tls"\n        "crypto/x509"\n        "fmt"\n        "github.com/Shopify/sarama"\n        "github.com/sirupsen/logrus"\n        "io/ioutil"\n        "time"\n    )\n    \n    const (\n        kafkaAddr     = "kafka.kafka:9092"\n        testTopicName = "mytopic"\n        certFile      = "/var/otterize/credentials/cert.pem"\n        keyFile       = "/var/otterize/credentials/key.pem"\n        rootCAFile    = "/var/otterize/credentials/ca.pem"\n    )\n    \n    func getTLSConfig() (*tls.Config, error) {\n        cert, err := tls.LoadX509KeyPair(certFile, keyFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading x509 key pair: %w", err)\n        }\n\n        pool := x509.NewCertPool()\n        rootCAPEM, err := ioutil.ReadFile(rootCAFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading root CA PEM file: %w ", err)\n        }\n        pool.AppendCertsFromPEM(rootCAPEM)\n        \n        return &tls.Config{\n            Certificates: []tls.Certificate{cert},\n            RootCAs:      pool,\n        }, nil\n    }\n\n    func loop_kafka() error {\n        addrs := []string{kafkaAddr}\n        \n        config := sarama.NewConfig()\n        fmt.Println("Loading mTLS certificates")\n        config.Net.TLS.Enable = true\n        tlsConfig, err := getTLSConfig()\n        if err != nil {\n            return err\n        }\n        config.Net.TLS.Config = tlsConfig\n        fmt.Println("Connecting to Kafka")\n        config.Net.DialTimeout = 5 * time.Second\n        config.Net.ReadTimeout = 5 * time.Second\n        config.Net.WriteTimeout = 5 * time.Second\n        client, err := sarama.NewClient(addrs, config)\n        if err != nil {\n            return err\n        }\n        fmt.Println("Creating a producer for -", testTopicName)\n        config.Producer.Return.Successes = true\n        config.Producer.Timeout = 5 * time.Second\n        config.Producer.Return.Errors = true\n        producer, err := sarama.NewSyncProducerFromClient(client)\n        if err != nil {\n            return err\n        }\n\n        fmt.Println("Sending messages")\n        i := 1\n        for {\n          msg := fmt.Sprintf("Message %d [sent by client-other]", i)\n          _, _, err = producer.SendMessage(&sarama.ProducerMessage{\n              Topic:     testTopicName,\n              Partition: -1,\n              Value:     sarama.StringEncoder(msg),\n          })\n          if err != nil {\n              return err\n          }\n          fmt.Printf("Sent message - %s\\n", msg)\n          time.Sleep(1 * time.Second)\n          i++\n        }\n        return nil\n    }\n\n    func main() {\n        for {\n            err := loop_kafka()\n            logrus.WithError(err).Println()\n            fmt.Println("Loop exited")\n            time.Sleep(2 * time.Second)\n        }\n    }\n\n\n  go.mod: |\n    module main\n            \n            go 1.18\n            \n            require (\n            github.com/Shopify/sarama v1.36.0\n            github.com/sirupsen/logrus v1.9.0\n            )\n            \n            require (\n            github.com/davecgh/go-spew v1.1.1 // indirect\n            github.com/eapache/go-resiliency v1.3.0 // indirect\n            github.com/eapache/go-xerial-snappy v0.0.0-20180814174437-776d5712da21 // indirect\n            github.com/eapache/queue v1.1.0 // indirect\n            github.com/golang/snappy v0.0.4 // indirect\n            github.com/hashicorp/errwrap v1.0.0 // indirect\n            github.com/hashicorp/go-multierror v1.1.1 // indirect\n            github.com/hashicorp/go-uuid v1.0.3 // indirect\n            github.com/jcmturner/aescts/v2 v2.0.0 // indirect\n            github.com/jcmturner/dnsutils/v2 v2.0.0 // indirect\n            github.com/jcmturner/gofork v1.7.6 // indirect\n            github.com/jcmturner/gokrb5/v8 v8.4.3 // indirect\n            github.com/jcmturner/rpc/v2 v2.0.3 // indirect\n            github.com/klauspost/compress v1.15.9 // indirect\n            github.com/pierrec/lz4/v4 v4.1.15 // indirect\n            github.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 // indirect\n            golang.org/x/crypto v0.0.0-20220722155217-630584e8d5aa // indirect\n            golang.org/x/net v0.0.0-20220809184613-07c6da5e1ced // indirect\n            golang.org/x/sys v0.0.0-20220728004956-3c1f35247d10 // indirect\n            )\n'))),(0,r.kt)(i.Z,{value:"client-authenticated-deployment.yaml",label:"client-authenticated-deployment.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client-authenticated\n  namespace: otterize-tutorial-kafka-mtls\nspec:\n  selector:\n    matchLabels:\n      app: client-authenticated\n  template:\n    metadata:\n      labels:\n        app: client-authenticated\n      annotations:\n        credentials-operator.otterize.com/tls-secret-name: client-authenticated-credentials-secret\n    spec:\n      containers:\n        - name: client-authenticated\n          image: golang\n          command: [ "/bin/sh", "-c", "--" ]\n          args: [ "while true; do cd /app; cp src/* .; go get main; go run .; sleep infinity; done" ]\n          volumeMounts:\n            - name: ephemeral\n              mountPath: /app\n            - mountPath: /app/src\n              name: client-authenticated-go\n            - name: otterize-credentials\n              mountPath: /var/otterize/credentials\n              readOnly: true\n      volumes:\n        - name: client-authenticated-go\n          configMap:\n            name: client-authenticated-go\n        - name: otterize-credentials\n          secret:\n            secretName: client-authenticated-credentials-secret\n        - name: ephemeral\n          emptyDir: { }\n'))),(0,r.kt)(i.Z,{value:"client-authenticated-configmap.yaml",label:"client-authenticated-configmap.yaml",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: client-authenticated-go\n  namespace: otterize-tutorial-kafka-mtls\ndata:\n  client-authenticated.go: |\n    package main\n    \n    import (\n        "crypto/tls"\n        "crypto/x509"\n        "fmt"\n        "github.com/Shopify/sarama"\n        "github.com/sirupsen/logrus"\n        "io/ioutil"\n        "time"\n    )\n    \n    const (\n        kafkaAddr     = "kafka.kafka:9092"\n        testTopicName = "transactions"\n        certFile      = "/var/otterize/credentials/cert.pem"\n        keyFile       = "/var/otterize/credentials/key.pem"\n        rootCAFile    = "/var/otterize/credentials/ca.pem"\n    )\n    \n    func getTLSConfig() (*tls.Config, error) {\n        cert, err := tls.LoadX509KeyPair(certFile, keyFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading x509 key pair: %w", err)\n        }\n\n        pool := x509.NewCertPool()\n        rootCAPEM, err := ioutil.ReadFile(rootCAFile)\n        if err != nil {\n            return nil, fmt.Errorf("failed loading root CA PEM file: %w ", err)\n        }\n        pool.AppendCertsFromPEM(rootCAPEM)\n        \n        return &tls.Config{\n            Certificates: []tls.Certificate{cert},\n            RootCAs:      pool,\n        }, nil\n    }\n\n    func loop_kafka() error {\n        addrs := []string{kafkaAddr}\n        \n        config := sarama.NewConfig()\n        fmt.Println("Loading mTLS certificates")\n        config.Net.TLS.Enable = true\n        tlsConfig, err := getTLSConfig()\n        if err != nil {\n            return err\n        }\n        config.Net.TLS.Config = tlsConfig\n        fmt.Println("Connecting to Kafka")\n        config.Net.DialTimeout = 5 * time.Second\n        config.Net.ReadTimeout = 5 * time.Second\n        config.Net.WriteTimeout = 5 * time.Second\n        client, err := sarama.NewClient(addrs, config)\n        if err != nil {\n            return err\n        }\n        fmt.Println("Creating a producer for -", testTopicName)\n        config.Producer.Return.Successes = true\n        config.Producer.Timeout = 5 * time.Second\n        config.Producer.Return.Errors = true\n        producer, err := sarama.NewSyncProducerFromClient(client)\n        if err != nil {\n            return err\n        }\n\n        fmt.Println("Sending messages")\n        i := 1\n        for {\n          msg := fmt.Sprintf("Message %d [sent by client-authenticated]", i)\n          _, _, err = producer.SendMessage(&sarama.ProducerMessage{\n              Topic:     testTopicName,\n              Partition: -1,\n              Value:     sarama.StringEncoder(msg),\n          })\n          if err != nil {\n              return err\n          }\n          fmt.Printf("Sent message - %s\\n", msg)\n          time.Sleep(1 * time.Second)\n          i++\n        }\n        return nil\n    }\n\n    func main() {\n        for {\n            err := loop_kafka()\n            logrus.WithError(err).Println()\n            fmt.Println("Loop exited")\n            time.Sleep(2 * time.Second)\n        }\n    }\n\n\n  go.mod: |\n    module main\n            \n            go 1.18\n            \n            require (\n            github.com/Shopify/sarama v1.36.0\n            github.com/sirupsen/logrus v1.9.0\n            )\n            \n            require (\n            github.com/davecgh/go-spew v1.1.1 // indirect\n            github.com/eapache/go-resiliency v1.3.0 // indirect\n            github.com/eapache/go-xerial-snappy v0.0.0-20180814174437-776d5712da21 // indirect\n            github.com/eapache/queue v1.1.0 // indirect\n            github.com/golang/snappy v0.0.4 // indirect\n            github.com/hashicorp/errwrap v1.0.0 // indirect\n            github.com/hashicorp/go-multierror v1.1.1 // indirect\n            github.com/hashicorp/go-uuid v1.0.3 // indirect\n            github.com/jcmturner/aescts/v2 v2.0.0 // indirect\n            github.com/jcmturner/dnsutils/v2 v2.0.0 // indirect\n            github.com/jcmturner/gofork v1.7.6 // indirect\n            github.com/jcmturner/gokrb5/v8 v8.4.3 // indirect\n            github.com/jcmturner/rpc/v2 v2.0.3 // indirect\n            github.com/klauspost/compress v1.15.9 // indirect\n            github.com/pierrec/lz4/v4 v4.1.15 // indirect\n            github.com/rcrowley/go-metrics v0.0.0-20201227073835-cf1acfcdf475 // indirect\n            golang.org/x/crypto v0.0.0-20220722155217-630584e8d5aa // indirect\n            golang.org/x/net v0.0.0-20220809184613-07c6da5e1ced // indirect\n            golang.org/x/sys v0.0.0-20220728004956-3c1f35247d10 // indirect\n            )\n'))))),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Deploy the two clients into a namespace called ",(0,r.kt)("inlineCode",{parentName:"li"},"otterize-tutorial-kafka-mtls")," using ",(0,r.kt)("inlineCode",{parentName:"li"},"kubectl"),":")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://docs.otterize.com/code-examples/kafka-mtls/all.yaml\n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Optional: check deployment status"),(0,r.kt)("p",null,"Check that the client pods were deployed:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl get pods -n otterize-tutorial-kafka-mtls\n")),(0,r.kt)("p",null,"You should see:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"NAME                                    READY   STATUS    RESTARTS   AGE\nclient-65695dfc4c-jf4hd                 1/1     Running   0          92s\nclient-authenticated-7c86974dc7-n6grt   1/1     Running   0          92s\nclient-other-7c4b8cbd8d-dpkt6           1/1     Running   0          92s\n"))),(0,r.kt)("p",null,"Let's monitor, in separate terminal windows, both clients' attempts to call Kafka,\nso we can see the effects of our changes in real time."),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Open a new terminal window ","[client]")," and tail the client log:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client\n")),(0,r.kt)("p",null,"This client should be able to communicate with the server:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Loading mTLS certificates\nConnecting to Kafka\nCreating a producer and a consumer for - mytopic\nSending messages\nSent message - Message 1 [sent by client]\nRead message - Message 1 [sent by client]\nRead message - Message 1 [sent by client-other]\nSent message - Message 2 [sent by client]\nRead message - Message 2 [sent by client-other]\nRead message - Message 2 [sent by client]\nRead message - Message 3 [sent by client-other]\nSent message - Message 3 [sent by client]\nRead message - Message 3 [sent by client]\n")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("strong",{parentName:"li"},"Open another terminal window ","[client-other]")," and tail the client-other log:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client-other\n")),(0,r.kt)("p",null,"This other client should also be able to communicate with the server:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Loading mTLS certificates\nConnecting to Kafka\nCreating a producer for - mytopic\nSending messages\nSent message - Message 1 [sent by client-other]\nSent message - Message 2 [sent by client-other]\nSent message - Message 3 [sent by client-other]\n")),(0,r.kt)("p",null,"If you've attached Otterize OSS to Otterize Cloud, you can now browse to your account at ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"https://app.otterize.com")," and see the access graph for your cluster:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Access graph",src:n(7120).Z,width:"1274",height:"765"})),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Why do I see six services?"),(0,r.kt)("p",null,"In addition to the Kafka service and the 3 clients we deployed, the network mapper also picked up the calls between the intents operator and Kafka, and between Kafka and zookeeper, so those discovered intents are reflected in the access graph (in light blue)."),(0,r.kt)("p",null,"The access graph also reflects an intent that's already been declared and applied, and was reported by the intents operator to the access graph: it's the intent which the intents operator created for itself to ensure it has access to Kafka. That's ",(0,r.kt)("a",{parentName:"p",href:"/reference/configuration/intents-operator/configuration"},"automatically generated")," by the intents operator when you apply the KafkaServerConfig: at that point the intents operator knows there is a Kafka service, and in order to ensure it can reach it and configure it, it declares its intent to do so. Specifically that will generate a network policy between the intents operator and the Kafka service, if network policies are in active enforcement and supported by your cluster, so the intents operator doesn't get blocked itself.")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Optional: tail the logs for client-authenticated"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client-authenticated\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Loading mTLS certificates\nConnecting to Kafka\nCreating a producer for - transactions\nSending messages\nSent message - Message 1 [sent by client-authenticated]\nSent message - Message 2 [sent by client-authenticated]\nSent message - Message 3 [sent by client-authenticated]\n"))),(0,r.kt)("h2",{id:"optional-install-otterize-cli-and-examine-topic-level-kafka-access-map"},"Optional: Install Otterize CLI and examine topic-level Kafka access map"),(0,r.kt)("p",null,"Now that our 3 clients are accessing our Kafka server, which has the Otterize OSS Kafka watcher enabled and feeding data to the network mapper, we can query the network mapper directly\nto see the map it has built of topic-level access by those clients."),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Install the Otterize CLI"),(0,r.kt)(o.Z,{groupId:"operating-systems",mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"mac",label:"Mac",default:!0,mdxType:"TabItem"},(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"Brew",label:"Brew",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"brew install otterize/otterize/otterize-cli\n"))),(0,r.kt)(i.Z,{value:"Apple Silicon",label:"Apple Silicon",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -LJO https://get.otterize.com/otterize-cli/v0.1.28/otterize_macOS_arm64_notarized.zip\ntar xf otterize_macOS_arm64_notarized.zip\nsudo cp otterize /usr/local/bin  # optionally move to PATH\n"))),(0,r.kt)(i.Z,{value:"Intel 64-bit",label:"Intel 64-bit",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl -LJO https://get.otterize.com/otterize-cli/v0.1.28/otterize_macOS_x86_64_notarized.zip\ntar xf otterize_macOS_x86_64_notarized.zip\nsudo cp otterize /usr/local/bin  # optionally move to PATH\n"))))),(0,r.kt)(i.Z,{value:"windows",label:"Windows",mdxType:"TabItem"},(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"Scoop",label:"Scoop",default:!0,mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-PowerShell"},"scoop bucket add otterize-cli https://github.com/otterize/scoop-otterize-cli\nscoop update\nscoop install otterize-cli\n"))),(0,r.kt)(i.Z,{value:"64-bit",label:"64-bit",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-PowerShell"},"Invoke-WebRequest -Uri https://get.otterize.com/otterize-cli/v0.1.28/otterize_Windows_x86_64.zip -OutFile otterize_Windows_x86_64.zip\nExpand-Archive otterize_Windows_x86_64.zip -DestinationPath .\n# optionally move to PATH\n"))))),(0,r.kt)(i.Z,{value:"linux",label:"Linux",mdxType:"TabItem"},(0,r.kt)(o.Z,{mdxType:"Tabs"},(0,r.kt)(i.Z,{value:"64-bit",label:"64-bit",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://get.otterize.com/otterize-cli/v0.1.28/otterize_Linux_x86_64.tar.gz\ntar xf otterize_Linux_x86_64.tar.gz\nsudo cp otterize /usr/local/bin  # optionally move to PATH\n")))))),(0,r.kt)("p",null,"More variants are available at the ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/otterize/otterize-cli/releases"},"GitHub Releases page"),".")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Query the mapper"),"1. List pod communication in our tutorial namespace:",(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"otterize network-mapper list -n otterize-tutorial-kafka-mtls\n")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"We should see all 3 of our clients producing data to topic ",(0,r.kt)("inlineCode",{parentName:"li"},"mytopic")," of our Kafka server:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"client in namespace otterize-tutorial-kafka-mtls calls:\n  - kafka in namespace kafka\n    - Kafka topic: mytopic, operations: [produce]\nclient-authenticated in namespace otterize-tutorial-kafka-mtls calls:\n  - kafka in namespace kafka\n    - Kafka topic: transactions, operations: [produce]\nclient-other in namespace otterize-tutorial-kafka-mtls calls:\n  - kafka in namespace kafka\n    - Kafka topic: mytopic, operations: [produce]\n")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Enabling the Kafka watcher component of the network mapper shows which clients connect to running Kafka servers, the topics they access, and the operations they undertake on those topics."),(0,r.kt)("p",{parentName:"admonition"},'The information is interesting for various purposes, including running Otterize in "shadow mode" to see what would happen in "enforcement mode" before actually turning on enforcement, and auto-generating client intents to bootstrap rolling out IBAC.'))),(0,r.kt)("h2",{id:"apply-intents"},"Apply intents"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"The client declares its intent to call the ",(0,r.kt)("inlineCode",{parentName:"li"},"kafka.kafka")," server with this ",(0,r.kt)("inlineCode",{parentName:"li"},"intents.yaml")," file:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: k8s.otterize.com/v1alpha2\nkind: ClientIntents\nmetadata:\n  name: client\n  namespace:  otterize-tutorial-kafka-mtls\nspec:\n  service:\n    name: client\n  calls:\n    - name: kafka.kafka\n      type: kafka\n      topics:\n        - name: mytopic\n          operations: [ all ]\n\n")),(0,r.kt)("admonition",{type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Client intents are the cornerstone of ",(0,r.kt)("a",{parentName:"p",href:"https://otterize.com/ibac"},"intent-based access control"),".")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"Keep an eye on the logs being tailed in the ",(0,r.kt)("strong",{parentName:"li"},"[client-other]")," while you apply this ",(0,r.kt)("inlineCode",{parentName:"li"},"intents.yaml")," file in your ",(0,r.kt)("strong",{parentName:"li"},"main terminal window")," using:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl apply -f https://docs.otterize.com/code-examples/kafka-mtls/client-intents.yaml\n")),(0,r.kt)("p",null,"You should quickly see in the ",(0,r.kt)("strong",{parentName:"p"},"[client-other]")," that the ",(0,r.kt)("strong",{parentName:"p"},"other client cannot")," access the topic:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'Sent message - Message 12 [sent by client-other]            # <- before applying the intents file\nSent message - Message 13 [sent by client-other]            # <- before applying the intents file\ntime="2022-10-06T09:44:53Z" level=info error="kafka server: # <- after applying the intents file\n The client is not authorized to access this topic"\nLoop exited\n')),(0,r.kt)("p",null,"Meanwhile, in the ",(0,r.kt)("strong",{parentName:"p"},"[client]")," terminal you can see that the ",(0,r.kt)("strong",{parentName:"p"},"client can")," access the topic:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Sent message - Message 24 [sent by client]\nRead message - Message 24 [sent by client]\nSent message - Message 25 [sent by client]\nRead message - Message 25 [sent by client]\n")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},"Verify that an ACL for this client was configured on the Kafka broker:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'kubectl logs -n kafka statefulset/kafka | grep "Processing Acl change" | grep mytopic | tail -n 1\n')),(0,r.kt)("p",null,"You should see:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"[2022-09-13 10:44:52,803] INFO Processing Acl change notification for\nResourcePattern(resourceType=TOPIC, name=mytopic, patternType=LITERAL),\nversionedAcls : Set(User:ANONYMOUS has DENY permission for operations:\nALL from hosts: *, User:CN=client.otterize-tutorial-kafka-mtls,O=SPIRE,C=US has ALLOW permission\nfor operations: ALL from hosts: *), zkVersion : 6 (kafka.security.authorizer.AclAuthorizer)\n")),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Optional: check that ",(0,r.kt)("b",null,"[client-authenticated]")," wasn't blocked"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl logs -f --tail 1 -n otterize-tutorial-kafka-mtls deploy/client-authenticated\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Loading mTLS certificates\nConnecting to Kafka\nCreating a producer for - transactions\nSending messages\nSent message - Message 263 [sent by client-authenticated]\nSent message - Message 264 [sent by client-authenticated]\nSent message - Message 265 [sent by client-authenticated]\n"))),(0,r.kt)("p",null,"If you've attached Otterize OSS to Otterize Cloud, go back to see the ",(0,r.kt)("a",{parentName:"p",href:"https://app.otterize.com"},"access graph in your browser"),". Click on the Kafka service, and click at the bottom of it to focus on it and show its details:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Access graph",src:n(4052).Z,width:"1276",height:"759"})),(0,r.kt)("p",null,"We can see what happened:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Kafka topic-specific intents from ",(0,r.kt)("strong",{parentName:"li"},"[client]")," are declared (solid black inner line and Kafka icon)."),(0,r.kt)("li",{parentName:"ol"},"Calls from ",(0,r.kt)("strong",{parentName:"li"},"[client-other]"),' are not declared (missing "white" inner line).'),(0,r.kt)("li",{parentName:"ol"},"Looking at the Kafka service, we can see that ",(0,r.kt)("strong",{parentName:"li"},"[client]")," has specific access configured (via Kafka ACLs) to perform ",(0,r.kt)("inlineCode",{parentName:"li"},"all")," operations on the ",(0,r.kt)("inlineCode",{parentName:"li"},"mytopic")," topic.")),(0,r.kt)("p",null,"Since discovered intents from the network mapper don't specify what specific topics and operations clients are performing (or attempting to perform), the access graph cannot show information on what is being blocked vs allowed (red vs green). That feature is in development."),(0,r.kt)("p",null,"Also, the access graph shows information about the mTLS certificates (credentials) distributed to the various services, as long as ",(0,r.kt)("a",{parentName:"p",href:"/security#cryptographic-credentials"},"Cloud-managed credentials")," are being used. Visibility for certificates distributed through an in-cluster SPIRE is in development."),(0,r.kt)("h2",{id:"what-did-we-accomplish"},"What did we accomplish?"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Controlling Kafka access no longer means touching ACLs, issuing and managing and distributing certs, establishing trust,\netc.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"As we saw with pod-to-pod access, clients simply declare with their intents files the Kafka access they need,\nand define a place on their filesystem where they'll get the appropriate credentials (certs).")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"The next ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl apply")," ensures that all the appropriate certs are issued and distributed,\nand that Kafka ACLs are configured to reflect precisely the intended topic-level access."))),(0,r.kt)("details",null,(0,r.kt)("summary",null,"Expand to see what happened behind the scenes"),(0,r.kt)("h3",{id:"one-time-setups"},"One-time setups:"),(0,r.kt)("p",null,"We configured the Helm chart for Kafka to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Allow the Otterize intents operator to be a Kafka super user (authenticated with a certificate)."),(0,r.kt)("li",{parentName:"ul"},"Use the SSL protocol for the Kafka listeners."),(0,r.kt)("li",{parentName:"ul"},"Let Otterize know it should generate mTLS credentials in the Java Key Store and Java Trust Store formats, and store them as a Kubernetes secret."),(0,r.kt)("li",{parentName:"ul"},"Use mTLS to authenticate clients, using this Kubernetes secret.")),(0,r.kt)("p",null,"We configured Kafka itself to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Add the TLS certificates of the Otterize credentials operator."),(0,r.kt)("li",{parentName:"ul"},"Set the default ACL for all topics to allow anonymous access.")),(0,r.kt)("h3",{id:"per-client-setups"},"Per-client setups:"),(0,r.kt)("p",null,"We configured each of our clients to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Let Otterize know it should generate mTLS credentials for that client."),(0,r.kt)("li",{parentName:"ul"},"Mount the Kubernetes secret in a local volume.")),(0,r.kt)("p",null,"This already enables mTLS authentication between both clients and Kafka."),(0,r.kt)("p",null,"Then we applied intents:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"We only declared that the ",(0,r.kt)("em",{parentName:"li"},"client")," pod (not the ",(0,r.kt)("em",{parentName:"li"},"client-other")," pod) needed to access the ",(0,r.kt)("inlineCode",{parentName:"li"},"mytopic")," topic.")),(0,r.kt)("p",null,"This allowed the ",(0,r.kt)("em",{parentName:"p"},"client")," pod its access and protected ",(0,r.kt)("inlineCode",{parentName:"p"},"mytopic")," from any unintended access, such as from ",(0,r.kt)("em",{parentName:"p"},"client-other"),".")),(0,r.kt)("admonition",{title:"Bonus tutorial",type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Try to create an intents file yourself for ",(0,r.kt)("strong",{parentName:"p"},"client-other"),", and apply it to allow this other client to access the topic.")),(0,r.kt)("h2",{id:"whats-next"},"What's next"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Follow ",(0,r.kt)("a",{parentName:"li",href:"/quick-visual-tutorials/visual-ibac-kafka-k8s"},"a more visual tutorial")," for securing Kafka with IBAC in a demo ecommerce application."),(0,r.kt)("li",{parentName:"ul"},"Learn how to easily secure pod-to-pod access with IBAC using Kubernetes network policies, in ",(0,r.kt)("a",{parentName:"li",href:"/quick-tutorials/k8s-network-policies"},"a hands-on tutorial")," or ",(0,r.kt)("a",{parentName:"li",href:"/quick-visual-tutorials/visual-ibac-network-policies"},"a more visual tutorial"),".")),(0,r.kt)("h2",{id:"teardown"},"Teardown"),(0,r.kt)("admonition",{type:"caution"},(0,r.kt)("p",{parentName:"admonition"},"Take care to remove the intents before removing the KafkaServerConfig or the Kafka broker, as the operator will not know how to remove\nthe intents if you first make it forget about the Kafka broker or it can't access the broker.\nIf it's unable to remove the ACLs for the intents, the operator will prevent the intents from being deleted until\nit is able to do so.")),(0,r.kt)("p",null,"To remove the deployed examples run:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"# run this first:\nkubectl delete -f https://docs.otterize.com/code-examples/kafka-mtls/client-intents.yaml\n# then the rest:\nkubectl delete -f https://docs.otterize.com/code-examples/kafka-mtls/all.yaml\nkubectl delete -f https://docs.otterize.com/code-examples/kafka-mtls/kafkaserverconfig.yaml\nhelm uninstall kafka -n kafka\n")))}d.isMDXComponent=!0},7120:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/base-14fcd94772a08136b170cbf9b3de61ad.png"},4052:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/protected-948b672ca746f3c854261cc2a14caf3e.png"}}]);
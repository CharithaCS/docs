---
sidebar_position: 1
title: Automate network policies
---
import CodeBlock from "@theme/CodeBlock";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Otterize automates network policies within your cluster by abstracting away
the management of pod identities, the labeling of clients, servers and namespaces,
and the manual authoring of individual network policies.

With intent-based access control, you just declare what client calls will be needed,
and everything is automatically wired together so only intended calls are allowed.

In this tutorial, we will:

- Deploy a server pod, and two clients calling it
- Declare that the client pod intends to call the server pod
- See that a network policy was autogenerated to allow just that

## Make sure you have a cluster that supports network policies
Before you start, you need to have a Kubernetes cluster with a [CNI](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/) that supports [NetworkPolicies](https://kubernetes.io/docs/concepts/services-networking/network-policies/).

{@include: ../_common/cluster-setup.md}

## Install Otterize

:::note
You can skip this section if Otterize is already installed in your cluster.
:::

{@include: ../_common/install-otterize.md}


## Deploy the server, client, client-other

Our simple example consists of three pods: an HTTP server and two clients that call it.

<details>
<summary>Expand to see the example YAML files</summary>
<Tabs>

<TabItem value="namespace.yaml" label="namespace.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/namespace.yaml}
```

</TabItem>

<TabItem value="server.yaml" label="server.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/server-deployment.yaml}
---
{@include: ../../static/code-examples/automate-network-policies/server-service.yaml}
```

</TabItem>
<TabItem value="client.yaml" label="client.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/client-deployment.yaml}
```

</TabItem>
<TabItem value="client-other.yaml" label="client-other.yaml" default>

```yaml
{@include: ../../static/code-examples/automate-network-policies/client-other-deployment.yaml}
```

</TabItem>

</Tabs>
</details>

Deploy the client, server, and the default deny network policy using `kubectl`.

   ```shell
   kubectl apply -f https://docs.otterize.com/code-examples/automate-network-policies/all.yaml
   ```

<details>
<summary>Optional: check deployment status</summary>
Check that the client and server pods were deployed

```bash
kubectl get pods -n otterize-tutorial-npol
```
You should see
```
NAME                           READY   STATUS    RESTARTS   AGE
client-596bcb48d5-pnjxc        1/1     Running   0          8s
client-other-f56d65d7f-z2wg2   1/1     Running   0          8s
server-6bb4784ccc-wtz7f        1/1     Running   0          8s
```
</details>

Let's monitor both client attempts to call the server with additional terminal windows,
so we can see the effects of our changes in real time.

**Open a new terminal window [client]** and tail the client log:
```bash
kubectl logs -f --tail 1 -n otterize-tutorial-npol deploy/client
```
At this point the client should be able to communicate with the server:
```
Calling server...
HTTP/1.1 200 OK
accept-ranges: bytes
cache-control: max-age=3600
last-modified: Mon, 03 Oct 2022 10:29:04 GMT
etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
content-length: 49
content-type: text/html; charset=UTF-8
Date: Mon, 03 Oct 2022 10:30:51 GMT
Connection: keep-alive
Keep-Alive: timeout=5

Hi, I am the server, you called, may I help you?
```

**Open another terminal window [client-other]** and tail the client-other log:
```bash
kubectl logs -f --tail 1 -n otterize-tutorial-npol deploy/client-other
```
At this point the client should be able to communicate with the server:
```
Calling server...
HTTP/1.1 200 OK
accept-ranges: bytes
cache-control: max-age=3600
last-modified: Mon, 03 Oct 2022 10:29:04 GMT
etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
content-length: 49
content-type: text/html; charset=UTF-8
Date: Mon, 03 Oct 2022 10:30:51 GMT
Connection: keep-alive
Keep-Alive: timeout=5

Hi, I am the server, you called, may I help you?
```

## Apply intents
We will now declare and apply intents to that allow traffic from the
**client** to the **server** by creating a custom resource ClientIntent).
Once the client declares its intents, Otterize will add a network policy to allow the intended calls
(**client** -> **server**) and fail all unintended calls (**client-other** -> **server**).

1. The client declares its intent to call the server with this `intents.yaml` file:

   ```yaml
   {@include: ../../static/code-examples/automate-network-policies/intents.yaml}
   ```

:::tip
Client intents are the cornerstone of [intent-based access control](https://otterize.com/ibac).
:::

   Keep an eye on the logs being tailed in the **[client-other]** terminal window
   while you apply this `intents.yaml` file in your **main terminal window** using:
   ```shell
   kubectl apply -f https://docs.otterize.com/code-examples/automate-network-policies/intents.yaml
   ```
2. You should quickly see in the **[client-other]** terminal that it times out when calling the server as expected:
   ```bash
   Calling server...
   HTTP/1.1 200 OK
   accept-ranges: bytes
   cache-control: max-age=3600
   last-modified: Mon, 03 Oct 2022 10:29:04 GMT
   etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
   content-length: 49
   content-type: text/html; charset=UTF-8
   Date: Mon, 03 Oct 2022 10:41:14 GMT
   Connection: keep-alive
   Keep-Alive: timeout=5

   Hi, I am the server, you called, may I help you?  # <- before applying the intents file
   # highlight-start
   Calling server...                                 # <- after applying the intents file
   curl timed out
   Calling server...
   curl timed out
   # highlight-end
   ```
:::tip
If the client isn't timing out, then the installed CNI plugin likely does not support network policies.
Consult the docs for your Kubernetes distribution or head back to the [Calico installation section](#make-sure-you-have-a-cni-network-plugin) to install one.
For example, minikube does not start by default with a CNI that supports network policies
but you can ask it to start with one that does, such as Calico.
:::

3. And in the **[client]** terminal you should see that calls go through as intended:
   ```bash
   Calling server...
   HTTP/1.1 200 OK
   accept-ranges: bytes
   cache-control: max-age=3600
   last-modified: Mon, 03 Oct 2022 10:29:04 GMT
   etag: W/"3557515-49-2022-10-03T10:29:04.343Z"
   content-length: 49
   content-type: text/html; charset=UTF-8
   Date: Mon, 03 Oct 2022 10:41:14 GMT
   Connection: keep-alive
   Keep-Alive: timeout=5

   Hi, I am the server, you called, may I help you?
   ```
4. You should also see that a new network policy was created:
   ```bash
   kubectl get NetworkPolicies -n otterize-tutorial-npol
   ```
   will output:
   ```
   NAME                                           POD-SELECTOR                                         AGE
   access-to-server-from-otterize-tutorial-npol   otterize/server=server-otterize-tutorial-np-7e16db   6s
   default-deny-ingress                           <none>                                               28s
   ```
:::tip Done!
Otterize did its job of both protecting *and* allowing intended access.
:::
## What did we accomplish?

- Controlling access through network policies no longer means touching network policies at all.

- Clients simply declare what they need to access with their intents files.

- The next `kubectl apply` ensures that network policies automatically reflect the intended pod-to-pod access.


<details>
<summary>Expand to see what happened behind the scenes</summary>

To generate network policies between two pods, for example called `client` and `server` running in
namespace `otterize-tutorial-npol` we needed to (in a simplified form):

1. Label the `server` pod with `otterize/server` and a unique value that represents this server - we will use this label in the network policy to apply it to all pods with
   this label (as an ingress rule).
2. Label the `client` pod with `otterize/access-to-server`, saying that this specific pod has access to `server` - we will
   use this label in the network policy as a filter &mdash; every
   pod that has the label saying [this pod can access the server] will be able to pass through the network policy.
3. Label the `client`'s namespace `otterize/namespace-name` with value `otterize-tutorial-npol` &mdash; this is used when intents refer to services in other namespaces.
4. Generate a network policy saying that
    1. Only pod with the label `otterize/access-to-server`
    2. From the namespaces with the label `otterize/namespace-name` and value `otterize-tutorial-npol`
    3. Can access pods with the label `otterize/server` and that matches this server

Otterize saved us from doing all this work by simply declaring the client's intents in `intents.yaml`,
while the appropriate network policies were managed automatically behind the scenes.

You can read the detailed explanation about how Otterize manages labels for network policies [here](/guides/k8s-ibac-via-network-policies/deeper-dive#track-artifacts).
</details>

:::info Bonus tutorial
Try to add an intents file yourself for client-other and apply it to allow access to the server.
:::

## What's next

- Configure [network policies](/guides/k8s-ibac-via-network-policies/) for your existing deployments.
- Explore the [network mapper](/quick-tutorials/k8s-network-mapper) to help you bootstrap intents files
  for use in IBAC.

## Teardown

To remove the deployed examples run:

```bash
kubectl delete namespace otterize-tutorial-npol
```
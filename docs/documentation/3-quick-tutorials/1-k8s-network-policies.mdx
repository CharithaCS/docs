---
sidebar_position: 1
title: Automate network policies
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Otterize automates network policies within your cluster by abstracting away
the management of pod identities, the labeling of clients, servers and namespaces,
and the manual authoring of individual network policies.

With intent-based access control, you just declare what client calls will be needed,
and everything is automatically wired together so only intended calls are allowed.

In this tutorial, we will

- Install Otterize in your Kubernetes cluster.
- Make sure your Kubernetes cluster has a CNI network plugin
- Deploy a server pod, and a client pod that calls it
- Deploy a "default deny" network policy to block undeclared calls
- Declare that the client pod intends to call the server pod
- See that a network policy was autogenerated to allow just that

## Install Otterize

:::note
You can skip this section if Otterize is already installed in your cluster.
:::

{@include: ../_common/install-otterize.md}

## Make sure you have a CNI network plugin

{@include: ../_common/verify-cni.md}

If you're not sure whether you have a CNI, you can just continue -- it'll soon become clear ;-).

## Deploy the server, client, and default network policy

Our simple example consists of two pods: an HTTP server and a client that calls it.

We also deploy a default-deny ingress network policy,
blocking pods from accepting incoming calls unless another network policy explicitly allows them.

<details>
<summary>Expand to see the details of this example...</summary>
<Tabs>

<TabItem value="namespace.yaml" label="namespace.yaml" default>

   ```yaml
   {@include: ../../../static/code-examples/network-policies/namespace.yaml}
   ```

</TabItem>

<TabItem value="server.yaml" label="server.yaml" default>

   ```yaml
  {@include: ../../../static/code-examples/network-policies/server-deployment.yaml}
   ---
  {@include: ../../../static/code-examples/network-policies/server-service.yaml}
  ```

</TabItem>
<TabItem value="client.yaml" label="client.yaml" default>

   ```yaml
   {@include: ../../../static/code-examples/network-policies/client-deployment.yaml}
   ```

</TabItem>

<TabItem value="default-deny.yaml" label="default-deny.yaml" default>

   ```yaml
   {@include: ../../../static/code-examples/network-policies/default-deny-network-policy.yaml}
   ```

</TabItem>
</Tabs>
</details>

1. Deploy the client, server, and the default deny network policy using `kubectl`.

   ```shell
   kubectl apply -f https://docs.otterize.com/code-examples/network-policies/all.yaml
   ```
2. Check that the `client` and `server` `pods` were deployed
   ```bash
   kubectl get pods -n otterize-tutorial-npol
   ```
   You should see
   ```
   NAME                      READY   STATUS    RESTARTS   AGE
   client-5689997b5c-grlnt   1/1     Running   0          35s
   server-6698c58cbc-v9n9b   1/1     Running   0          34s
   ```
3. Check that the default deny ingress network policy was deployed:
   ```bash
   kubectl get NetworkPolicies -n otterize-tutorial-npol
   ```
   You should see
   ```
   NAME                   POD-SELECTOR   AGE
   default-deny-ingress   <none>         17s
   ```
4. Let's monitor the client's attempts to call the server with a second terminal window,
   so we can see the effects of our changes in real time.

   **Open a second terminal window** and tail the client log:
   ```bash
   kubectl logs -f --tail 1 -n otterize-tutorial-npol deploy/client
   ```
   At this point the client should be timing out when trying to call the server:
   ```
   Calling server...
   curl timed out
   Calling server...
   curl timed out
   Calling server...
   curl timed out
   ```

:::tip
   If the client isn't timing out, then you may not have a CNI installed, or your CNI may not support network policies.
   Consult the docs for your Kubernetes distribution.
   For example, vanilla minikube does not start by default with a CNI that supports network policies
   but you can ask it to start with one that does, such as Calico.
:::

   The client failing like that is the expected outcome since by default all pods' ingress are blocked by the default network policy.
   Once the client declares its intents, Otterize will add a network policy to allow the intended calls.
   Let's see that now...

## Apply intents

1. The client declares its intent to call the server with this `intents.yaml` file:

   ```yaml
   {@include: ../../../static/code-examples/network-policies/intents.yaml}
   ```
:::tip
Client intents are the cornerstone of [intent-based access control](otterize.com/ibac).
:::

   Keep an eye on the logs being tailed in the **second terminal window**
   while you apply this `intents.yaml` file in your **main terminal window** using:
   ```shell
   kubectl apply -f https://docs.otterize.com/code-examples/network-policies/intents.yaml
   ```
2. You should quickly see in the **second terminal** that the client is now successfully calling the server:
   ```bash
   Calling server...
   curl timed out
   Calling server...
   curl timed out                              <- before applying the intents file
   # highlight-start
   Calling server...                           <- after applying the intents file
   HTTP/1.1 200 OK
   X-App-Name: http-echo
   X-App-Version: 0.2.3
   Date: Wed, 07 Sep 2022 13:51:34 GMT
   Content-Length: 12
   Content-Type: text/plain; charset=utf-8
   
   Hi, I am the server, you called, may I help you?
   # highlight-end
   ```

3. If you check, you should see that a new network policy was created
   ```bash
   kubectl get NetworkPolicies -n otterize-tutorial-npol
   ```
   You should see
   ```
   NAME                                           POD-SELECTOR                                         AGE
   access-to-server-from-otterize-tutorial-npol   otterize/server=server-otterize-tutorial-np-7e16db   6s
   default-deny-ingress                           <none>                                               28s
   ```

:::danger Uri: write celebration
TODO
:::

:::tip
To learn more about how Otterize + network policies work see
details [here](/documentation/intents-operator/network-policies/in-depth)
:::

## What happened behind the scenes
:::danger requires re-write, labels aren't correct.
This is the [updated](/documentation/guides/k8s-ibac-via-network-policies#track-artifacts) version
:::
To generate network policies between two pods, for example called `client` and `server` running in
namespace `otterize-tutorial-npol` we needed to:

1. Label the `server` pod `label-server` - we will use this label in the network policy to apply it to all pods with
   this label (as an ingress rule).
2. Label the `client` pod with `has-access-to-server`, saying that this specific pod has access to `server` - we will
   use this label in the network policy as a filter -- every
   pod that has the label saying [this pod can access the server] will be able to pass through the network policy.
3. Label the `client`'s namespace `label-otterize-tutorial-npol` -- this is a requirement for the network policy as
   another filtering mechanism for pods.
4. Generate a network policy saying that
    1. Only pod with the label `has-access-to-server`
    2. From the namespaces with the label `label-otterize-tutorial-npol`
    3. Can access pods with the label `label-server`

Otterize saved us from doing all this work by simply declaring the client's intents in `intents.yaml`,
while the appropriate network policies were managed automatically behind the scenes.

## What's next

<!-- [Intents Operator](/documentation/intents-operator): -->

- Configure [network policies](/documentation/intents-operator/network-policies) for your existing deployments.
- Explore the [network mapper](/documentation/getting-started/network-policies) to help you bootstrap intents you can.
  apply as network policies.

## Teardown

To remove the deployed resources run

```bash
kubectl delete namespace otterize-tutorial-npol
```
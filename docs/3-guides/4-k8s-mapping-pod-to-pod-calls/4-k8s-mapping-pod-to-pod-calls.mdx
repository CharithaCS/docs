---
title: Mapping pod-to-pod calls in Kubernetes
---
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

The Network Mapper allows you to map pod-to-pod traffic within your K8s cluster. This tutorial will guide you
through installing Otterize, mapping traffic and tracking changes.

## Install the network mapper

{@include: ../../_common/install-otterize-network-mapper.md}

## Install the Otterize CLI

{@include: ../../_common/install-otterize-cli.md}


## Retrieving the network map (list, YAML intents, and JSON)

{@include: ../../_common/network-mapper/intents-list-export.md}

:::info
See the [Network Mapper documentation](/network-mapper/intro) for more details about the CLI.
:::

### Filtering by namespace
One of the CLI's more useful flags is the namespace filter. You can query the mapper for calls originating only from a specific namespace with
```bash
otterize mapper list -n {NAMESPACE}
```

### Resting the mapper state
The Otterize network mapper keeps track of active connections as long as its running. You can clear its state by calling
```bash
otterize mapper mapper reset
```

For the complete list of the otterize network mapper capabilities as read the [CLI command reference](/cli/#network-mapper).

## Change traffic -> Sniff&Diff

One of the benefits for using the network mapper is the ability to track changes over time for communication within your
cluster.

1. Let's save the current state of traffic from the cluster into a file we will compare against later
   ```shell
   otterize mapper list > intents-original.txt
   ```

2. And now we can add traffic to the cluster and see how the Network Mapper tracks it. You can do that by deploying our
   example
   which consists of two pods: client and server, communicating over HTTP. Deploy example:
   ```shell
   kubectl apply -n otterize-tutorial-mapper -f https://docs.otterize.com/code-examples/network-mapper/all.yaml
   ```

<details>
<summary>Check that the client and server pods were deployed</summary>

```bash
kubectl get pods -n otterize-tutorial-mapper
```
You should see
```
NAME                      READY   STATUS    RESTARTS   AGE
client-756f7677f8-d6qdq   1/1     Running   0          45s
server-6698c58cbc-ssxvx   1/1     Running   0          45s
```
</details>

3. Export the updated observed intents.
   ```shell
   otterize mapper list
   ```
   You will now see the client and server pods communication in addition
   to the previously observed traffic.
   ```shell
   # highlight-start
   client calls:
     - server
   # highlight-end

   checkoutservice in namespace ecom-demo calls:
     - orderservice

   orderservice in namespace ecom-demo calls:
     - kafka
   ```
5. We can also compare both output to see the difference. We'll start by saving the updated state to a file with
   ```bash
   otterize mapper list > intents-updated.txt
   ```
6. And compare the original file with the updated file using
   ```bash
   diff --color=always -y intents-original.txt intents-updated.txt;echo
   ```
   You should see a result looking like
   ```bash
                                                       > client calls:
                                                       >   - server
                                                       >
   checkoutservice in namespace ecom-demo calls:       checkoutservice in namespace ecom-demo calls:
     - orderservice                                      - orderservice

   orderservice in namespace ecom-demo calls:          orderservice in namespace ecom-demo calls:
     - kafka                                             - kafka
      ```


## What calls are picked up

Otterize identifies pod-to-pod traffic by tracking
### Active TCP connections
Any two `pods` communicating over TCP have a record on the respective `nodes` they are running on
we can use to identify the connection.
### DNS responses
DNS is a common network protocol used for service discovery. When a `pod` [checkout-service] queries for a `service`
[order-service] within K8s multiple queries are generated for multiple DNS suffixes such as: [order-service.prod] and
[order-service.prod.svc.cluster.local]. To learn more about how K8s works with DNS for service discovery
read [here](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/).

By tracking only DNS responses Otterize lowers computational requirements as it only processes packets with relevant
data &mdash; DNS answers (e.g. [order-service] is located at address [X.X.X.X]).

Connections are then mapped and resolved back to pod-level (human-readable) identities (e.g. `checkoutservice` calls the `orderservice`).


:::tip
Checkout this blog by Evyatar Meged about how we implemented this feature.
:::

## Network mapping for bootstrapping access controls
Otterize network mapper can export captured traffic as intents by calling
```bash
otterize mapper export
```
Which exports intents as concatenated ClientIntents CRDs looking like this
```yaml
apiVersion: k8s.otterize.com/v1alpha1
kind: ClientIntents
metadata:
  name: frontend
  namespace: otterize-ecom-demo
spec:
  service:
    name: frontend
  calls:
    - name: checkoutservice
      type: HTTP
---
apiVersion: k8s.otterize.com/v1alpha1
kind: ClientIntents
metadata:
  name: checkoutservice
  namespace: otterize-ecom-demo
spec:
  service:
    name: checkoutservice
  calls:
    - name: productcatalogservice
      type: HTTP
```

You can directly apply these CRDs to K8s and Otterize will enforce network policies according to them automatically.
:::tip
To learn more about how to use ClientIntents CRDs to manage network policies read this [guide](/guides/k8s-ibac-via-network-policies/)
:::

## What's next

- Use your mapped traffic as intents and implement [IBAC via network policies](/guides/k8s-ibac-via-network-policies/).


## Current limitations

* UDP sessions between pods aren't resolved using the "Tracking active connections" method.
* DNS response tracking is relevant for clusters using DNS for service discovery
